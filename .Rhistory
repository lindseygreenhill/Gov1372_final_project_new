arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = name, y = n)) +
geom_col(aes(fill = party), stat = "identity") +
theme_clean()
name_top %>%
arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = name, y = n)) +
geom_col(stat = "identity") +
theme_clean()
name_top %>%
arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col(stat = "identity") +
theme_clean()
name_top %>%
arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = reorder(name, -n), y = n)) +
geom_col(stat = "identity") +
theme_clean()
name_top %>%
arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = reorder(name, -n), y = n)) +
geom_col() +
coord_flip() +
theme_clean()
name_top %>%
arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col() +
coord_flip() +
theme_clean()
name_top %>%
arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col(fill = party) +
coord_flip() +
theme_clean()
name_top %>%
arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col(aes(fill = party)) +
coord_flip() +
theme_clean()
name_top %>%
arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col(aes(fill = party)) +
scale_fill_manual(values = c("navyblue", "red")) +
coord_flip() +
theme_clean()
name_top %>%
arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col(aes(fill = party)) +
scale_fill_manual(values = c("navyblue", "indianred")) +
coord_flip() +
theme_clean()
party_count_plot <- joined_data %>%
group_by(party) %>%
drop_na() %>%
count() %>%
ggplot(aes(x = party, y = n)) +
geom_col(aes(fill = party)) +
scale_fill_manual(values = c("darkblue", "green", "indianred")) +
labs(title = "Total Tweets by Party",
"Democrats tweet the most",
x = "Party",
y = "") +
theme_clean()
party_count_plot
ggsave(plot = party_count_plot, "plots/party_summary_plot.png")
name_top %>%
arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col(aes(fill = party)) +
scale_fill_manual(values = c("navyblue", "indianred")) +
coord_flip() +
theme_clean()
name_top %>%
arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col(aes(fill = party)) +
scale_fill_manual(values = c("navyblue", "indianred")) +
coord_flip() +
labs(x = "Name", y = "Total Tweets",
title = "Total Amount of Tweets") +
theme_clean()
name_top %>%
arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col(aes(fill = party)) +
scale_fill_manual(values = c("navyblue", "indianred")) +
coord_flip() +
labs(x = "Name", y = "Total Tweets",
title = "Total Amount of Tweets",
subtitle = "Top 20 tweeters") +
theme_clean()
tweets_name_plot <- name_top %>%
arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col(aes(fill = party)) +
scale_fill_manual(values = c("navyblue", "indianred")) +
coord_flip() +
labs(x = "Name", y = "Total Tweets",
title = "Total Amount of Tweets",
subtitle = "Top 20 tweeters") +
theme_clean()
ggsave(plot = tweets_name_plot, "plots/tweets_by_name_plot.png")
knitr::opts_chunk$set(echo = TRUE)
library(quanteda)
library(skimr)
library(lubridate)
library(ggthemes)
library(spacyr)
library(tidyverse)
load("data_collection/tweets_training_data.RData")
load("data_collection/twitter_handles.RData")
quanteda_options(reset = TRUE)
quanteda_options("pattern_hashtag" = NULL)
text_corpus <- corpus(joined_data, text_field = "text")
knitr::opts_chunk$set(echo = TRUE)
library(quanteda)
library(skimr)
library(lubridate)
library(ggthemes)
library(spacyr)
library(tidyverse)
load("data_collection/tweets_training_data.RData")
load("data_collection/twitter_handles.RData")
# I need to join the training data with the congress data so I have more info on
# the candidates. I am also filtering out independents because it is not in the
# scope of this project
joined_data <- training_data %>%
left_join(twitter_handles, by = c("screen_name" = "handle")) %>%
filter(party != "I")
quanteda_options(reset = TRUE)
quanteda_options("pattern_hashtag" = NULL)
text_corpus <- corpus(joined_data, text_field = "text")
?gsub
text_corpus
toks_1 <- tokens(text_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar = 3) %>%
tokens_ngrams(n = 1)
dfm_1 <- dfm(toks_1, groups = "party")
keyness_dic_R <- textstat_keyness(dfm_1, target = "R")
keyness_plot <- textplot_keyness(keyness_dic_R,
margin = .2,
n = 20L,
color = c("indianred", "navyblue"),
labelsize = 6) +
labs(title = "Keyness Plot Republican and Democrat Tweets") +
theme(plot.title = element_text(size = 25),
legend.text = element_text(size = 25),
axis.title.x = element_text(size = 20))
keyness_plot
tweet_dfm <- corpus(joined_data, text_field = "text")
tweet_dfm <- tokens(corpus(joined_data, text_field = "text"),
remove_punct = TRUE) %>%
dfm()
tag_dfm <- dfm_select(tweet_dfm, pattern = "#*")
tag_dfm <- dfm_select(tweet_dfm, pattern = "#*")
toptag <- names(topfeatures(tag_dfm, 50))
tag_fcm <- fcm(tag_dfm)
toptag <- names(topfeatures(tag_dfm, 50))
tag_dfm <- dfm_select(tweet_dfm, pattern = "#*")
tag_fcm <- fcm(tag_dfm)
install.packages("quanteda.textplots")
library(quanteda.textplots)
tag_fcm <- fcm(tag_dfm)
head(toptag)
head(tweet_dfm)
tag_dfm <- dfm_select(tweet_dfm, pattern = "#*")
toptag <- names(topfeatures(tag_dfm, 50))
head(toptag)
toptag <- names(topfeatures(tag_dfm, 2))
head(toptag)
toks_1 <- tokens(text_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar = 3) %>%
tokens_ngrams(n = 1) %>%
tokens_wordstem()
dfm_1 <- dfm(toks_1, groups = "party")
word_cloud_plot <- textplot_wordcloud(dfm_1, comparison = T, min_count = 2300,
color = c("navyblue", "indianred"))
word_cloud_plot <- textplot_wordcloud(dfm_1, comparison = T, min_count = 2300,
color = c("navyblue", "indianred"))
word_cloud_plot
keyness_dic_R <- textstat_keyness(dfm_1, target = "R")
keyness_plot <- textplot_keyness(keyness_dic_R,
margin = .2,
n = 20L,
color = c("indianred", "navyblue"),
labelsize = 6) +
labs(title = "Keyness Plot Republican and Democrat Tweets") +
theme(plot.title = element_text(size = 25),
legend.text = element_text(size = 25),
axis.title.x = element_text(size = 20))
keyness_plot
knitr::opts_chunk$set(echo = TRUE)
library(quanteda)
library(skimr)
library(lubridate)
library(ggthemes)
library(spacyr)
library(tidyverse)
load("data_collection/tweets_training_data.RData")
load("data_collection/twitter_handles.RData")
# I need to join the training data with the congress data so I have more info on
# the candidates. I am also filtering out independents because it is not in the
# scope of this project
joined_data <- training_data %>%
left_join(twitter_handles, by = c("screen_name" = "handle")) %>%
filter(party != "I")
# visualizing the data set -- looking at amount of tweets over time. WHAT IS THE OUTLIER??
time_plot <- training_data %>%
group_by(date) %>%
count() %>%
ggplot(aes(x = date, y = n)) +
geom_point() +
theme_clean() +
labs(title = "Daily Number of Tweets",
x = "Date",
y = "")
time_plot
ggsave(plot = time_plot,"plots/time_summary_plot.png")
# tweets by party
party_count_plot <- joined_data %>%
group_by(party) %>%
drop_na() %>%
count() %>%
ggplot(aes(x = party, y = n)) +
geom_col(aes(fill = party)) +
scale_fill_manual(values = c("darkblue", "indianred")) +
labs(title = "Total Tweets by Party",
"Democrats tweet the most",
x = "Party",
y = "") +
theme_clean()
party_count_plot
ggsave(plot = party_count_plot, "plots/party_summary_plot.png")
# tweets by person
name_top <- joined_data %>%
group_by(name, party) %>%
count() %>%
arrange(desc(n)) %>%
head(20)
tweets_name_plot <- name_top %>%
arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col(aes(fill = party)) +
scale_fill_manual(values = c("navyblue", "indianred")) +
coord_flip() +
labs(x = "Name", y = "Total Tweets",
title = "Total Amount of Tweets",
subtitle = "Top 20 tweeters") +
theme_clean()
tweets_name_plot
# ggsave(plot = tweets_name_plot, "plots/tweets_by_name_plot.png")
# this fixes the hashtag problem
quanteda_options(reset = TRUE)
quanteda_options("pattern_hashtag" = NULL)
# now I'm going to do the quanteda stuff
text_corpus <- corpus(joined_data, text_field = "text")
# Because we are doing dictionaries it might be better to do single words
# instead of phrases. Owen thoughts?
toks_1 <- tokens(text_corpus,
remove_punct = TRUE,
remove_symbols = TRUE,
remove_numbers = TRUE,
remove_url = TRUE) %>%
tokens_tolower() %>%
tokens_remove(pattern=stopwords("en")) %>%
tokens_select(min_nchar = 3) %>%
tokens_ngrams(n = 1) %>%
tokens_wordstem()
# I guess I will do a wordcloud because why not
dfm_1 <- dfm(toks_1, groups = "party")
# setting the minimum threshold to 2300 because then I only get one warning
# message
word_cloud_plot <- textplot_wordcloud(dfm_1, comparison = T, min_count = 2300,
color = c("navyblue", "indianred"))
word_cloud_plot
# making the keyness stat stuff
# Keyness Comparison
keyness_dic_R <- textstat_keyness(dfm_1, target = "R")
keyness_plot <- textplot_keyness(keyness_dic_R,
margin = .2,
n = 20L,
color = c("indianred", "navyblue"),
labelsize = 6) +
labs(title = "Keyness Plot Republican and Democrat Tweets") +
theme(plot.title = element_text(size = 25),
legend.text = element_text(size = 25),
axis.title.x = element_text(size = 20))
keyness_plot
ggsave(plot = keyness_plot, filename = "plots/word_dictionary")
keyness_plot
ggsave(filename = "plots/word_dictionary")
ggsave(filename = "plots/word_dictionary.png")
View(joined_data)
library(readxl)
library(janitor)
library(skimr)
library(rtweet)
library(tidyverse)
twitter_handles_senate <- read_excel("data_collection/data/congress_twitter_092721.xlsx",
sheet = 1,
skip = 1) %>%
clean_names() %>%
mutate(member = "senate")
twitter_handles_house <- read_excel("data_collection/data/congress_twitter_092721.xlsx",
sheet = 2,
skip = 1) %>%
clean_names() %>%
mutate(member = "house")
twitter_handles <- twitter_handles_house %>%
rbind(twitter_handles_senate) %>%
mutate(handle = str_sub(link, start = 21)) %>%
select(-link)
skim(twitter_handles)
unique(joined_data$screen_name)
load("~/Desktop/Gov1372_final_project_new/data_collection/tweets_complete.RData")
skim(tweets_complete)
skim(dfm_1)
View(dfm_1)
version
View(tweets_tidy)
skim(tweets_tidy)
knitr::opts_chunk$set(echo = TRUE)
library(quanteda)
library(skimr)
library(lubridate)
library(ggthemes)
library(spacyr)
library(tidyverse)
load("data_collection/tweets_training_data.RData")
load("data_collection/twitter_handles.RData")
# visualizing the data set -- looking at amount of tweets over time. WHAT IS THE OUTLIER??
time_plot <- training_data %>%
group_by(date) %>%
count() %>%
ggplot(aes(x = date, y = n)) +
geom_point() +
theme_clean() +
labs(title = "Daily Number of Tweets",
x = "Date",
y = "")
time_plot
# ggsave(plot = time_plot,"plots/time_summary_plot.png")
# tweets by party
party_count_plot <- joined_data %>%
group_by(party) %>%
drop_na() %>%
count() %>%
ggplot(aes(x = party, y = n)) +
geom_col(aes(fill = party)) +
scale_fill_manual(values = c("darkblue", "indianred")) +
labs(title = "Total Tweets by Party",
"Democrats tweet the most",
x = "Party",
y = "") +
theme_clean()
party_count_plot
# ggsave(plot = party_count_plot, "plots/party_summary_plot.png")
# tweets by person
name_top <- joined_data %>%
group_by(name, party) %>%
count() %>%
arrange(desc(n)) %>%
head(20)
tweets_name_plot <- name_top %>%
arrange(desc(n)) %>%
drop_na() %>%
ggplot(aes(x = reorder(name, n), y = n)) +
geom_col(aes(fill = party)) +
scale_fill_manual(values = c("navyblue", "indianred")) +
coord_flip() +
labs(x = "Name", y = "Total Tweets",
title = "Total Amount of Tweets",
subtitle = "Top 20 tweeters") +
theme_clean()
tweets_name_plot
# ggsave(plot = tweets_name_plot, "plots/tweets_by_name_plot.png")
tweets_tidy %>%
group_by(name) %>%
count()
tweets_tidy %>%
group_by(screen_name) %>%
count()
library(ggthemes)
library(ggpubr)
tweets_tidy %>%
group_by(screen_name) %>%
count() %>%
ggplot(aes(x = n)) +
geom_histogram() +
theme_clean()
tweets_tidy %>%
group_by(screen_name) %>%
count() %>%
ggplot(aes(x = n)) +
geom_histogram() +
theme_clean() +
labs(title = "Distribution of Total Tweets",
x = "Total Tweets",
y = "Count")
tweets_hist <- tweets_tidy %>%
group_by(screen_name) %>%
count() %>%
ggplot(aes(x = n)) +
geom_histogram() +
theme_clean() +
labs(title = "Distribution of Total Tweets",
x = "Total Tweets",
y = "Count")
ggsave(tweets_hist, filename = "plots/total_tweets_hist.png")
tweets_tidy %>%
group_by(screen_name) %>%
count() %>%
ggplot(aes(x = n)) +
geom_histogram() +
theme_clean() +
labs(title = "Distribution of Total Tweets",
x = "Total Tweets",
y = "Count") +
theme(plot.title = element_text(size = 12))
tweets_tidy %>%
group_by(screen_name) %>%
count() %>%
ggplot(aes(x = n)) +
geom_histogram() +
theme_clean() +
labs(title = "Distribution of Total Tweets",
x = "Total Tweets",
y = "Count") +
theme(plot.title = element_text(size = 17))
tweets_tidy %>%
group_by(screen_name) %>%
count() %>%
ggplot(aes(x = n)) +
geom_histogram() +
theme_clean() +
labs(title = "Distribution of Total Tweets",
x = "Total Tweets",
y = "Count") +
theme(plot.title = element_text(size = 17),
axis.text = element_text(size = 15),
axis.title = element_text(size = 16))
tweets_tidy %>%
group_by(screen_name) %>%
count() %>%
ggplot(aes(x = n)) +
geom_histogram() +
theme_clean() +
labs(title = "Distribution of Total Tweets",
x = "Total Tweets",
y = "Count") +
theme(plot.title = element_text(size = 20),
axis.text = element_text(size = 15),
axis.title = element_text(size = 16))
t
tweets_hist <- tweets_tidy %>%
group_by(screen_name) %>%
count() %>%
ggplot(aes(x = n)) +
geom_histogram() +
theme_clean() +
labs(title = "Distribution of Total Tweets",
x = "Total Tweets",
y = "Count") +
theme(plot.title = element_text(size = 20),
axis.text = element_text(size = 15),
axis.title = element_text(size = 16))
ggsave(tweets_hist, filename = "plots/total_tweets_hist.png")
training_data
training_data %>%
filter(party == "I")
training_data %>% filter(party == "I")
training_data %>%
left_join(twitter_handles, by = c("screen_name" = "handle")) %>% filter(party == "I")
training_data %>%
left_join(twitter_handles, by = c("screen_name" = "handle")) %>% filter(party == "I") %>% unique(name)
training_data %>%
left_join(twitter_handles, by = c("screen_name" = "handle")) %>% filter(party == "I") %>% unique(screen_name)
training_data %>%
left_join(twitter_handles, by = c("screen_name" = "handle")) %>% filter(party == "I") %>% View()

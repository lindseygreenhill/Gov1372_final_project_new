---
title: "bias_analysis"
author: "Lindsey Greenhill"
date: "12/8/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(gt)
library(quanteda)
library(broom)
library(skimr)
library(lubridate)
library(janitor)
library(dotwhisker)
library(tidytext)
library(haven)
library(ggthemes)
library(webshot)
library(stargazer)
library(tidyverse)
library(patchwork)
library(ggrepel)
library(ggpubr)
load("data_collection/tweets_testing_data.RData")
load("data_collection/twitter_handles.RData")

joined_data <- testing_data %>%
  left_join(twitter_handles, by = c("screen_name" = "handle")) %>%
  filter(party != "I")

nom_scores <- read_csv("data_collection/data/nominate_data.csv") %>%
  mutate(name = tolower(bioname)) %>%
  filter(congress == 117,
         chamber != "President") %>%
  select(name, nominate_dim1, party_code) %>%
  mutate(last_name = sapply(strsplit(name, ","), "[", 1)) %>%
  mutate(party = if_else(party_code == 200, "R", "D"))
```


```{r}

# I am now going to give each tweet a score

# dictionary from word dictionary analysis

content_dict <- dictionary(list(republican = c("biden",
                                               "border",
                                               "democrat",
                                               "spend",
                                               "illeg",
                                               "china",
                                               "inflat",
                                               "pelosi",
                                               "trillion",
                                               "afghanistan",
                                               "polici",
                                               "southern",
                                               "communist",
                                          "bidenbordercrisi",
                                          "radic",
                                          "mandat",
                                          "joe",
                                          "dem",
                                          "taxpay",
                                          "socialist"),
                                democrat = c("black",
                                             "work",
                                             "payment",
                                             "violenc",
                                             "vote",
                                             "act",
                                             "childtaxcredit",
                                             "pandem",
                                             "democraci",
                                             "communiti",
                                             "famili",
                                             "child",
                                             "help",
                                             "buildbackbett",
                                             "pass",
                                             "care",
                                             "invest",
                                             "climat",
                                        "americanrescueplan",
                                        "health")))

```


```{r}
# creating text corpus

text_corpus <- corpus(joined_data, text_field = "text")

# creating dfm for cocntent analysis

content_toks <- tokens(text_corpus,
               remove_punct = TRUE,
               remove_symbols = TRUE,
               remove_numbers = TRUE,
               remove_url = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(pattern=stopwords("en")) %>%
  tokens_select(min_nchar = 3)

content_dfm <- dfm(content_toks, groups = c("name", "date", "party"))

# selecting words in the dictionaries

content_categories <- dfm_lookup(content_dfm, dictionary = content_dict)

# turning dfm into dataframe

content_df <- convert(content_categories, to = "data.frame")

# changing the quanteda object into a data frame

content_df_cleaned <- content_df %>%
   mutate(party = substr(doc_id, start = str_length(doc_id), stop = str_length(doc_id)),
          name = substr(doc_id, start = 1, stop = str_length(doc_id) - 13))
```


```{r echo=FALSE, message=FALSE, results="asis"}

# calculating the language score of each tweet

score_df <- content_df_cleaned %>%
  mutate(language_score = republican - democrat)

# creating the average for each congressperson. I'm also joining with the
# nominate scores data

avg_df <- score_df %>%
  group_by(name, party) %>%
  summarise(avg_language_score = mean(language_score, na.rm = T)) %>%
  mutate(republican = if_else(party == "R", 1, 0),
         name = tolower(name)) %>%
  mutate(last_name = sapply(strsplit(name, ","), "[", 1)) %>%
  left_join(nom_scores, by = c("last_name", "party"))

# I have to hand code some values in

avg_df <- avg_df %>%
  mutate(nominate_dim1 = case_when(last_name == "bishop jr." ~ as.double(-.283),
                                   last_name == "herrera butler" ~ as.double(.352),
                                   last_name == "murrary" ~ as.double(-.352),
                                   last_name == "pallone jr." ~ as.double(-.404),
                                   last_name == "pascrell jr." ~ as.double(-.366),
                                   last_name == "payne jr." ~ as.double(-.518),
                                   last_name == "rodgers" ~ as.double(.424),
                                   TRUE ~ nominate_dim1)) %>%
  mutate(nominate_score = 100*nominate_dim1)

# now I am going to do the regression 

mod_1 <- lm(avg_language_score ~ republican, data = avg_df)

mod_1_plot <- avg_df %>%
  ggplot(aes(x = republican, y = avg_language_score)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_clean() +
  labs(title = "Language Score ~ Republican")
mod_1_plot
# ggsave(filename = "plots/language_score_vs_republican_plot.png")

# now I am doing regresison by nom scores

mod_2 <- lm(avg_language_score ~ nominate_score, data = avg_df)

mod_2_plot <- avg_df %>%
  ggplot(aes(x = nominate_score, y = avg_language_score)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_clean() +
  labs(title = "Language Score ~ Nominate Score")
mod_2_plot
# ggsave(filename = "plots/language_score_vs_nom_score_plot.png")

stargazer(mod_1, mod_2,
          type = "latex")
```


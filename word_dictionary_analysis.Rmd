---
title: "word_dictionary_analysis"
author: "Lindsey Greenhill"
date: "11/15/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(quanteda)
library(skimr)
library(lubridate)
library(ggthemes)
library(spacyr)
library(tidyverse)
load("data_collection/tweets_training_data.RData")
load("data_collection/twitter_handles.RData")

```


```{r echo=FALSE}

# I need to join the training data with the congress data so I have more info on
# the candidates. I am also filtering out independents because it is not in the
# scope of this project

joined_data <- training_data %>%
  left_join(twitter_handles, by = c("screen_name" = "handle")) %>%
  filter(party != "I")
```

## Summary Plots 

```{r echo=FALSE}
# visualizing the data set -- looking at amount of tweets over time. WHAT IS THE OUTLIER??

time_plot <- training_data %>%
  group_by(date) %>% 
  count() %>%
  ggplot(aes(x = date, y = n)) +
  geom_point() +
  theme_clean() +
  labs(title = "Daily Number of Tweets",
       x = "Date",
       y = "")

time_plot
# ggsave(plot = time_plot,"plots/time_summary_plot.png")

# tweets by party

party_count_plot <- joined_data %>%
  group_by(party) %>%
  drop_na() %>%
  count() %>%
  ggplot(aes(x = party, y = n)) +
  geom_col(aes(fill = party)) +
  scale_fill_manual(values = c("darkblue", "indianred")) +
  labs(title = "Total Tweets by Party",
       "Democrats tweet the most",
       x = "Party",
       y = "") +
  theme_clean()

party_count_plot

# ggsave(plot = party_count_plot, "plots/party_summary_plot.png")

# tweets by person

name_top <- joined_data %>%
  group_by(name, party) %>%
  count() %>%
  arrange(desc(n)) %>%
  head(20)

tweets_name_plot <- name_top %>%
  arrange(desc(n)) %>%
  drop_na() %>%
  ggplot(aes(x = reorder(name, n), y = n)) +
  geom_col(aes(fill = party)) +
  scale_fill_manual(values = c("navyblue", "indianred")) +
  coord_flip() +
  labs(x = "Name", y = "Total Tweets",
       title = "Total Amount of Tweets",
       subtitle = "Top 20 tweeters") +
  theme_clean() 

tweets_name_plot
# ggsave(plot = tweets_name_plot, "plots/tweets_by_name_plot.png")




```


## Wordcloud Analysis

```{r echo=FALSE, warning=FALSE, fig.width=10, fig.height=10}

# this fixes the hashtag problem 

quanteda_options(reset = TRUE)
quanteda_options("pattern_hashtag" = NULL)

# now I'm going to do the quanteda stuff

text_corpus <- corpus(joined_data, text_field = "text")


# Because we are doing dictionaries it might be better to do single words
# instead of phrases. Owen thoughts?

toks_1 <- tokens(text_corpus,
                 remove_punct = TRUE,
                 remove_symbols = TRUE,
                 remove_numbers = TRUE,
                 remove_url = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(pattern=stopwords("en")) %>%
  tokens_select(min_nchar = 3) %>%
  tokens_ngrams(n = 1) %>%
  tokens_wordstem()

# I guess I will do a wordcloud because why not

dfm_1 <- dfm(toks_1, groups = "party")

# setting the minimum threshold to 2300 because then I only get one warning
# message

word_cloud_plot <- textplot_wordcloud(dfm_1, comparison = T, min_count = 2300,
                   color = c("navyblue", "indianred"))
word_cloud_plot



```

## Keyness Analysis

```{r echo=FALSE, fig.width=10.5, fig.height=10}

# making the keyness stat stuff

# Keyness Comparison

keyness_dic_R <- textstat_keyness(dfm_1, target = "R")
keyness_plot <- textplot_keyness(keyness_dic_R,
                 margin = .2,
                 n = 20L,
                 color = c("indianred", "navyblue"),
                 labelsize = 6) +
  labs(title = "Keyness Plot Republican and Democrat Tweets") +
  theme(plot.title = element_text(size = 25),
        legend.text = element_text(size = 25),
        axis.title.x = element_text(size = 20))

keyness_plot

# ggsave(filename = "plots/word_dictionary.png")


```


